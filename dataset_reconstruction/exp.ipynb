{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "train.csv not found in /home/da23c014/PrivacyAI/CourseProject/datasets/fer2013 or corrupted. You can download it from https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFER2013\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/da23c014/PrivacyAI/CourseProject/datasets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rec/lib/python3.8/site-packages/torchvision/datasets/fer2013.py:44\u001b[0m, in \u001b[0;36mFER2013.__init__\u001b[0;34m(self, root, split, transform, target_transform)\u001b[0m\n\u001b[1;32m     42\u001b[0m data_file \u001b[38;5;241m=\u001b[39m base_folder \u001b[38;5;241m/\u001b[39m file_name\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(\u001b[38;5;28mstr\u001b[39m(data_file), md5\u001b[38;5;241m=\u001b[39mmd5):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or corrupted. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can download it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_samples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     52\u001b[0m         (\n\u001b[1;32m     53\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mDictReader(file)\n\u001b[1;32m     57\u001b[0m     ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: train.csv not found in /home/da23c014/PrivacyAI/CourseProject/datasets/fer2013 or corrupted. You can download it from https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.FER2013('/home/da23c014/PrivacyAI/CourseProject/datasets', split='train',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "dataset = torchvision.datasets.FER2013('/home/da23c014/PrivacyAI/CourseProject/datasets', split='train',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=torch.utils.data.DataLoader(dataset, 100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(y0):\n",
    "    labels_dict = {0: -1, 1: -1, 2: 0, 3: 1, 4: -1, 5: -1, 6: -1, 7: -1, 8: -1, 9: -1}\n",
    "    y0 = torch.stack([torch.tensor(labels_dict[int(cur_y)]) for cur_y in y0])\n",
    "    return y0\n",
    "\n",
    "\n",
    "def get_balanced_data( data_loader, data_amount):\n",
    "    print('BALANCING DATASET...')\n",
    "    # get balanced data\n",
    "    data_amount_per_class = data_amount // 2\n",
    "\n",
    "    labels_counter = {1: 0, 0: 0}\n",
    "    x0, y0 = [], []\n",
    "    got_enough = False\n",
    "    for bx, by in data_loader:\n",
    "        by = create_labels(by)\n",
    "        for i in range(len(bx)):\n",
    "            if int(by[i])==-1:\n",
    "                continue\n",
    "            elif labels_counter[int(by[i])] < data_amount_per_class:\n",
    "                labels_counter[int(by[i])] += 1\n",
    "                x0.append(bx[i])\n",
    "                y0.append(by[i])\n",
    "            if (labels_counter[0] >= data_amount_per_class) and (labels_counter[1] >= data_amount_per_class):\n",
    "                got_enough = True\n",
    "                break\n",
    "        if got_enough:\n",
    "            break\n",
    "    x0, y0 = torch.stack(x0), torch.stack(y0)\n",
    "    return x0, y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALANCING DATASET...\n"
     ]
    }
   ],
   "source": [
    "x0, y0 = get_balanced_data(k, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming x0 is your tensor with shape [500, 1, 48, 48]\n",
    "# Extract the first image\n",
    "\n",
    "image_tensor = x0[(y0==0)][56] # Shape will be [1, 48, 48]\n",
    "\n",
    "# Remove the channel dimension (1), changing shape to [48, 48]\n",
    "image_tensor = image_tensor.squeeze(0)\n",
    "\n",
    "# Convert the tensor to a numpy array\n",
    "image_np = image_tensor.numpy()\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_np, cmap='gray')\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into train and test sets with stratification on 'emotion' label.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '/home/da23c014/PrivacyAI/CourseProject/datasets/fer2013/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Stratified split on the 'emotion' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.35, stratify=df['emotion'], random_state=42)\n",
    "\n",
    "# Save the split datasets\n",
    "train_df.to_csv('/home/da23c014/PrivacyAI/CourseProject/datasets/fer2013/train.csv', index=False)\n",
    "test_df.to_csv('/home/da23c014/PrivacyAI/CourseProject/datasets/fer2013/test.csv', index=False)\n",
    "\n",
    "print(\"Data has been split into train and test sets with stratification on 'emotion' label.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '/home/da23c014/PrivacyAI/CourseProject/datasets/fer2013/train.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    4690\n",
       "6    3227\n",
       "4    3139\n",
       "2    2663\n",
       "0    2597\n",
       "5    2061\n",
       "1     283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '/home/da23c014/PrivacyAI/CourseProject/datasets/fer2013/test.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    2525\n",
       "6    1738\n",
       "4    1691\n",
       "2    1434\n",
       "0    1398\n",
       "5    1110\n",
       "1     153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
